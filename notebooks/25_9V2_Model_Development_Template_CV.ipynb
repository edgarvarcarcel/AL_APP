{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mk2cQAl9BrC7"
   },
   "source": [
    "# **0. Introduction**\n",
    "With this notebook you can define:\n",
    "\n",
    "1. Preprocessing method : If you want to perform scaling or not\n",
    "2. Over / under sampling method.\n",
    "3. Feature Selection Method\n",
    "4. Methods for handle nans\n",
    "5. Hyperparameters of the Pytorch Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5048,
     "status": "ok",
     "timestamp": 1715801900206,
     "user": {
      "displayName": "Edgar David Varcarcel Trujillo",
      "userId": "04708129325083286457"
     },
     "user_tz": 300
    },
    "id": "GGHrhsUkB3k0",
    "outputId": "a12535ad-4dea-4dc5-8880-c335178023d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported.\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "\n",
    "# Data Manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Plots\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Data preprocessing\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy import stats\n",
    "\n",
    "# Data splitting\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Feature Selection\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Models\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import torch as th\n",
    "from torch import Tensor\n",
    "from torch.nn.parameter import Parameter\n",
    "\n",
    "# Feature Selection\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "# Oversampling\n",
    "from imblearn.over_sampling import SMOTE , SMOTENC , ADASYN , BorderlineSMOTE , KMeansSMOTE ,SVMSMOTE\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import confusion_matrix , f1_score , precision_score , recall_score , make_scorer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_curve, roc_auc_score , precision_recall_curve, average_precision_score , accuracy_score\n",
    "\n",
    "# Hyperparameter optimization\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Data imputation\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "# Feature importance\n",
    "import shap\n",
    "\n",
    "# Utils\n",
    "from itertools import product\n",
    "import json\n",
    "import time\n",
    "import warnings\n",
    "import pickle\n",
    "from scipy.interpolate import make_interp_spline\n",
    "from scipy.interpolate import interp1d\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# Set Numpy Seed\n",
    "np.random.seed(0)\n",
    "#plt.style.use('ggplot')\n",
    "print('Libraries imported.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GLOBAL PARAMETERS:\n",
      "FEATURE_SELECTION : F_CLASSIF\n",
      "SAMPLING : ADASYN\n",
      "PERFORM_SCALING : YES\n",
      "NAN_HANDLE : KNN\n",
      "PYTORCH_PARAMETERS : {'hidden_sizes': [[100, 100, 50, 100, 100]], 'dropout_prob': [0.1], 'class_weights': [[1.0, 2.0]], 'BATCH_SIZE': [16]}\n",
      "\n",
      "Experiment Name: F_CLASSIF-ADASYN-YES-KNN\n"
     ]
    }
   ],
   "source": [
    "# Define parameters of how to run the notebook\n",
    "# Posible options\n",
    "\"\"\"\n",
    "GLOBAL_PARAMETERS = {'FEATURE_SELECTION' : ['XGBOOST' , 'VARIANCE_THRESHOLD' , 'F_CLASSIF' , 'RFE' , 'NONE' , 'ALL_FEATURE_SELECTION_METHODS'],\n",
    "                    'SAMPLING' : ['SMOTE' , 'ADASYN' , 'BORDERLINE_SMOTE', 'NONE' , 'ALL_OVERSAMPLING_METHODS'],\n",
    "                    'PERFORM_SCALING' : ['YES' , 'NO'],\n",
    "                    'NAN_HANDLE' : ['DROP_ALL' , 'MASK_ALL' , 'DROP_PERCENT' , KNN],\n",
    "                    'PYTORC_PARAMETERS' : {}}\n",
    "\"\"\"\n",
    "GLOBAL_PARAMETERS = {'FEATURE_SELECTION' :  'F_CLASSIF',\n",
    "                    'SAMPLING' : 'ADASYN' ,\n",
    "                    'PERFORM_SCALING' : 'YES',\n",
    "                    'NAN_HANDLE' : 'KNN' ,\n",
    "                    'PYTORCH_PARAMETERS' : {'hidden_sizes' : [ [100 , 100 , 50 , 100 , 100]],\n",
    "                                            'dropout_prob' : [0.1],\n",
    "                                            'class_weights' : [[1.0 , 2.0]],\n",
    "                                           'BATCH_SIZE' : [16]}}\n",
    "\n",
    "# Assert that the selection is ok\n",
    "assert GLOBAL_PARAMETERS['FEATURE_SELECTION'] in ['XGBOOST' , 'VARIANCE_THRESHOLD' , 'F_CLASSIF' , 'RFE' , 'NONE' , 'ALL_FEATURE_SELECTION_METHODS']\n",
    "assert GLOBAL_PARAMETERS['SAMPLING'] in ['SMOTE' , 'ADASYN' , 'BORDERLINE_SMOTE' , 'NONE' , 'ALL_OVERSAMPLING_METHODS']\n",
    "assert GLOBAL_PARAMETERS['PERFORM_SCALING'] in ['YES' , 'NO']\n",
    "assert GLOBAL_PARAMETERS['NAN_HANDLE'] in ['DROP_ALL' , 'MASK_ALL' , 'DROP_PERCENT' , 'KNN']\n",
    "\n",
    "print('GLOBAL PARAMETERS:')\n",
    "for _ in GLOBAL_PARAMETERS.keys():\n",
    "    print(_ , ':' , GLOBAL_PARAMETERS[_])\n",
    "\n",
    "MODEL_NAME = '-'.join([_ for _ in GLOBAL_PARAMETERS.values() if _ not in [GLOBAL_PARAMETERS['PYTORCH_PARAMETERS']]])\n",
    "print('\\nExperiment Name:' ,MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 739
    },
    "executionInfo": {
     "elapsed": 3976,
     "status": "ok",
     "timestamp": 1715801908962,
     "user": {
      "displayName": "Edgar David Varcarcel Trujillo",
      "userId": "04708129325083286457"
     },
     "user_tz": 300
    },
    "id": "ACCUsyi3B3fs",
    "outputId": "78a68a71-dfc4-4016-c63f-31db6ce3b718"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>record_id</th>\n",
       "      <th>data_group</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>bmi</th>\n",
       "      <th>active_smoking</th>\n",
       "      <th>pack_years</th>\n",
       "      <th>alcohol_abuse</th>\n",
       "      <th>real_function_ckd_stages</th>\n",
       "      <th>preoperative_hemoglobin_level</th>\n",
       "      <th>...</th>\n",
       "      <th>approach</th>\n",
       "      <th>conversion</th>\n",
       "      <th>type_of_anastomosis -&gt; das von UK sind alles  Ileocolonic anastomosis</th>\n",
       "      <th>anastomotic_technique</th>\n",
       "      <th>anastomotic_configuration</th>\n",
       "      <th>protective_stomy</th>\n",
       "      <th>surgeon_experience</th>\n",
       "      <th>anastomotic_leackage</th>\n",
       "      <th>BIHistoryOfIschaemicHeartDisease</th>\n",
       "      <th>BIHistoryOfDiabetes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5921</td>\n",
       "      <td>clarunisclaraspita</td>\n",
       "      <td>1.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.6</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>59231</td>\n",
       "      <td>clarunisclaraspita</td>\n",
       "      <td>1.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>19.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.3</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>592-82</td>\n",
       "      <td>clarunisclaraspita</td>\n",
       "      <td>2.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>18.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.7</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>592-92</td>\n",
       "      <td>clarunisclaraspita</td>\n",
       "      <td>1.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>22.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.9</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>59251</td>\n",
       "      <td>clarunisclaraspita</td>\n",
       "      <td>1.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>17.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.7</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5906</th>\n",
       "      <td>473-772</td>\n",
       "      <td>university_wrzburg</td>\n",
       "      <td>2.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>20.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.6</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5907</th>\n",
       "      <td>473-806</td>\n",
       "      <td>university_wrzburg</td>\n",
       "      <td>2.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5908</th>\n",
       "      <td>473-808</td>\n",
       "      <td>university_wrzburg</td>\n",
       "      <td>2.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>22.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.7</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5909</th>\n",
       "      <td>473-830</td>\n",
       "      <td>university_wrzburg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>24.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.2</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5910</th>\n",
       "      <td>473-92</td>\n",
       "      <td>university_wrzburg</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5911 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     record_id          data_group  sex   age   bmi  active_smoking  \\\n",
       "0         5921  clarunisclaraspita  1.0  87.0   NaN             1.0   \n",
       "1        59231  clarunisclaraspita  1.0  53.0  19.2             1.0   \n",
       "2       592-82  clarunisclaraspita  2.0  71.0  18.8             0.0   \n",
       "3       592-92  clarunisclaraspita  1.0  39.0  22.4             0.0   \n",
       "4        59251  clarunisclaraspita  1.0  67.0  17.2             1.0   \n",
       "...        ...                 ...  ...   ...   ...             ...   \n",
       "5906   473-772  university_wrzburg  2.0  24.0  20.4             0.0   \n",
       "5907   473-806  university_wrzburg  2.0  87.0  32.0             0.0   \n",
       "5908   473-808  university_wrzburg  2.0  74.0  22.7             1.0   \n",
       "5909   473-830  university_wrzburg  1.0  85.0  24.3             0.0   \n",
       "5910    473-92  university_wrzburg  2.0   NaN  14.8             0.0   \n",
       "\n",
       "      pack_years  alcohol_abuse  real_function_ckd_stages  \\\n",
       "0           25.0            2.0                       5.0   \n",
       "1           35.0            3.0                       1.0   \n",
       "2            NaN            3.0                       1.0   \n",
       "3            0.0            3.0                       2.0   \n",
       "4           75.0            3.0                       1.0   \n",
       "...          ...            ...                       ...   \n",
       "5906         NaN            3.0                       1.0   \n",
       "5907         NaN            3.0                       4.0   \n",
       "5908        20.0            3.0                       1.0   \n",
       "5909         NaN            3.0                       2.0   \n",
       "5910         NaN            3.0                       NaN   \n",
       "\n",
       "      preoperative_hemoglobin_level  ...  approach  conversion  \\\n",
       "0                               9.6  ...       1.0         NaN   \n",
       "1                              11.3  ...       3.0         NaN   \n",
       "2                              13.7  ...       3.0         0.0   \n",
       "3                              11.9  ...       3.0         0.0   \n",
       "4                               7.7  ...       3.0         NaN   \n",
       "...                             ...  ...       ...         ...   \n",
       "5906                           13.6  ...       1.0         NaN   \n",
       "5907                            NaN  ...       3.0         NaN   \n",
       "5908                            9.7  ...       3.0         NaN   \n",
       "5909                           13.2  ...       3.0         NaN   \n",
       "5910                            NaN  ...       NaN         1.0   \n",
       "\n",
       "      type_of_anastomosis -> das von UK sind alles  Ileocolonic anastomosis  \\\n",
       "0                                                   3.0                       \n",
       "1                                                   3.0                       \n",
       "2                                                   3.0                       \n",
       "3                                                   3.0                       \n",
       "4                                                   3.0                       \n",
       "...                                                 ...                       \n",
       "5906                                                3.0                       \n",
       "5907                                                3.0                       \n",
       "5908                                                3.0                       \n",
       "5909                                                3.0                       \n",
       "5910                                                3.0                       \n",
       "\n",
       "      anastomotic_technique  anastomotic_configuration  protective_stomy  \\\n",
       "0                       2.0                        1.0               3.0   \n",
       "1                       1.0                        3.0               3.0   \n",
       "2                       NaN                        1.0               3.0   \n",
       "3                       1.0                        3.0               3.0   \n",
       "4                       1.0                        3.0               3.0   \n",
       "...                     ...                        ...               ...   \n",
       "5906                    2.0                        2.0               3.0   \n",
       "5907                    2.0                        2.0               3.0   \n",
       "5908                    1.0                        3.0               3.0   \n",
       "5909                    2.0                        2.0               3.0   \n",
       "5910                    2.0                        NaN               3.0   \n",
       "\n",
       "      surgeon_experience  anastomotic_leackage  \\\n",
       "0                    1.0                     0   \n",
       "1                    1.0                     0   \n",
       "2                    1.0                     0   \n",
       "3                    1.0                     0   \n",
       "4                    1.0                     0   \n",
       "...                  ...                   ...   \n",
       "5906                 1.0                     0   \n",
       "5907                 1.0                     0   \n",
       "5908                 1.0                     0   \n",
       "5909                 1.0                     0   \n",
       "5910                 NaN                     0   \n",
       "\n",
       "      BIHistoryOfIschaemicHeartDisease  BIHistoryOfDiabetes  \n",
       "0                                    0                    0  \n",
       "1                                    0                    0  \n",
       "2                                    0                    0  \n",
       "3                                    0                    0  \n",
       "4                                    1                    0  \n",
       "...                                ...                  ...  \n",
       "5906                                 0                    0  \n",
       "5907                                 0                    0  \n",
       "5908                                 0                    1  \n",
       "5909                                 0                    0  \n",
       "5910                                 0                    0  \n",
       "\n",
       "[5911 rows x 37 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "input_path = r'..\\data'\n",
    "input_filename = r'\\reduced_op_UK_merged_data_final_21062024.csv'\n",
    "df = pd.read_csv(input_path + input_filename , decimal = '.' , sep = ';')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1715801918340,
     "user": {
      "displayName": "Edgar David Varcarcel Trujillo",
      "userId": "04708129325083286457"
     },
     "user_tz": 300
    },
    "id": "czayG8DjZddE",
    "outputId": "f1e3a261-fb7a-48e2-d701-2235102047d3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "uk                    3041\n",
       "university_wrzburg     647\n",
       "university_dalhous     340\n",
       "university_of_east     314\n",
       "military_universit     294\n",
       "university_vilnius     234\n",
       "university_basel       226\n",
       "university_hamburg     220\n",
       "university_las_veg     173\n",
       "kantonspital_liest     106\n",
       "universitt_innsbru     103\n",
       "gzo_wetzikon            90\n",
       "emmental_hospital       67\n",
       "clarunisclaraspita      56\n",
       "Name: data_group, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show group distribution\n",
    "df['data_group'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['clarunisclaraspita',\n",
       " 'emmental_hospital',\n",
       " 'gzo_wetzikon',\n",
       " 'kantonspital_liest',\n",
       " 'military_universit',\n",
       " 'uk',\n",
       " 'universitt_innsbru',\n",
       " 'university_basel',\n",
       " 'university_dalhous',\n",
       " 'university_hamburg',\n",
       " 'university_las_veg',\n",
       " 'university_of_east',\n",
       " 'university_vilnius',\n",
       " 'university_wrzburg']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save total of data groups\n",
    "clinics = df['data_group'].unique().tolist()\n",
    "clinics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1715801921370,
     "user": {
      "displayName": "Edgar David Varcarcel Trujillo",
      "userId": "04708129325083286457"
     },
     "user_tz": 300
    },
    "id": "FIrKEQ9IZksT",
    "outputId": "275e2afd-061c-422c-86ba-932e880352f7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['record_id',\n",
       " 'data_group',\n",
       " 'sex',\n",
       " 'age',\n",
       " 'bmi',\n",
       " 'active_smoking',\n",
       " 'pack_years',\n",
       " 'alcohol_abuse',\n",
       " 'real_function_ckd_stages',\n",
       " 'preoperative_hemoglobin_level',\n",
       " 'preoperative_leukocyte_count',\n",
       " 'preoperative_albumin_level',\n",
       " 'preoperative_crp_level',\n",
       " 'liver_metastasis_at_time_of_anastomosis',\n",
       " 'neoadjuvant_therapy',\n",
       " 'preoperative_use_of_immunosuppressive_drugs',\n",
       " 'preoperative_steroid_use',\n",
       " 'dosage_of_steroids',\n",
       " 'preoperative_nsaids_use',\n",
       " 'preoperative_blood_transfusion',\n",
       " 'tnf_alpha_inhib',\n",
       " 'asa_score',\n",
       " 'prior_abdominal_surgery',\n",
       " 'indication',\n",
       " 'operation',\n",
       " 'emergency_surgery',\n",
       " 'perforation',\n",
       " 'approach',\n",
       " 'conversion',\n",
       " 'type_of_anastomosis -> das von UK sind alles  Ileocolonic anastomosis',\n",
       " 'anastomotic_technique',\n",
       " 'anastomotic_configuration',\n",
       " 'protective_stomy',\n",
       " 'surgeon_experience',\n",
       " 'anastomotic_leackage',\n",
       " 'BIHistoryOfIschaemicHeartDisease',\n",
       " 'BIHistoryOfDiabetes']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print columns of the data\n",
    "df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1715801924796,
     "user": {
      "displayName": "Edgar David Varcarcel Trujillo",
      "userId": "04708129325083286457"
     },
     "user_tz": 300
    },
    "id": "kOSaw6tI7yli"
   },
   "outputs": [],
   "source": [
    "# Drop columns to omit\n",
    "drop_columns = ['record_id']\n",
    "df = df.drop(columns = drop_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1715801925918,
     "user": {
      "displayName": "Edgar David Varcarcel Trujillo",
      "userId": "04708129325083286457"
     },
     "user_tz": 300
    },
    "id": "BP2nbR9WB3Yc"
   },
   "outputs": [],
   "source": [
    "# Define target variable\n",
    "TARGET = ['anastomotic_leackage']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kUsNFqsICrC1"
   },
   "source": [
    "# **1. NAN Handle**\n",
    "\n",
    "Here is defined the process of how to handle nan values.\n",
    "\n",
    "1. If DROP_ALL, then all rows with nans are removed \n",
    "2. If MASK_ALL, then all rows with nans are masked with -1\n",
    "3. If DROP_PERCENT, then only features with a percent of missing are dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>bmi</th>\n",
       "      <th>active_smoking</th>\n",
       "      <th>pack_years</th>\n",
       "      <th>alcohol_abuse</th>\n",
       "      <th>real_function_ckd_stages</th>\n",
       "      <th>preoperative_hemoglobin_level</th>\n",
       "      <th>preoperative_leukocyte_count</th>\n",
       "      <th>preoperative_albumin_level</th>\n",
       "      <th>...</th>\n",
       "      <th>conversion</th>\n",
       "      <th>type_of_anastomosis -&gt; das von UK sind alles  Ileocolonic anastomosis</th>\n",
       "      <th>anastomotic_technique</th>\n",
       "      <th>anastomotic_configuration</th>\n",
       "      <th>protective_stomy</th>\n",
       "      <th>surgeon_experience</th>\n",
       "      <th>anastomotic_leackage</th>\n",
       "      <th>BIHistoryOfIschaemicHeartDisease</th>\n",
       "      <th>BIHistoryOfDiabetes</th>\n",
       "      <th>data_group_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.6</td>\n",
       "      <td>6.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>19.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.3</td>\n",
       "      <td>12.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>18.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.7</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>22.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.9</td>\n",
       "      <td>8.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>17.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.7</td>\n",
       "      <td>8.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5906</th>\n",
       "      <td>2.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>20.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.6</td>\n",
       "      <td>4.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5907</th>\n",
       "      <td>2.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5908</th>\n",
       "      <td>2.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>22.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.7</td>\n",
       "      <td>9.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5909</th>\n",
       "      <td>1.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>24.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.2</td>\n",
       "      <td>4.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5910</th>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5911 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      sex   age   bmi  active_smoking  pack_years  alcohol_abuse  \\\n",
       "0     1.0  87.0   NaN             1.0        25.0            2.0   \n",
       "1     1.0  53.0  19.2             1.0        35.0            3.0   \n",
       "2     2.0  71.0  18.8             0.0         NaN            3.0   \n",
       "3     1.0  39.0  22.4             0.0         0.0            3.0   \n",
       "4     1.0  67.0  17.2             1.0        75.0            3.0   \n",
       "...   ...   ...   ...             ...         ...            ...   \n",
       "5906  2.0  24.0  20.4             0.0         NaN            3.0   \n",
       "5907  2.0  87.0  32.0             0.0         NaN            3.0   \n",
       "5908  2.0  74.0  22.7             1.0        20.0            3.0   \n",
       "5909  1.0  85.0  24.3             0.0         NaN            3.0   \n",
       "5910  2.0   NaN  14.8             0.0         NaN            3.0   \n",
       "\n",
       "      real_function_ckd_stages  preoperative_hemoglobin_level  \\\n",
       "0                          5.0                            9.6   \n",
       "1                          1.0                           11.3   \n",
       "2                          1.0                           13.7   \n",
       "3                          2.0                           11.9   \n",
       "4                          1.0                            7.7   \n",
       "...                        ...                            ...   \n",
       "5906                       1.0                           13.6   \n",
       "5907                       4.0                            NaN   \n",
       "5908                       1.0                            9.7   \n",
       "5909                       2.0                           13.2   \n",
       "5910                       NaN                            NaN   \n",
       "\n",
       "      preoperative_leukocyte_count  preoperative_albumin_level  ...  \\\n",
       "0                              6.4                         0.0  ...   \n",
       "1                             12.4                         0.0  ...   \n",
       "2                              9.0                         0.0  ...   \n",
       "3                              8.8                         0.0  ...   \n",
       "4                              8.6                         0.0  ...   \n",
       "...                            ...                         ...  ...   \n",
       "5906                           4.9                         NaN  ...   \n",
       "5907                           NaN                         NaN  ...   \n",
       "5908                           9.2                         NaN  ...   \n",
       "5909                           4.7                         NaN  ...   \n",
       "5910                          13.4                         NaN  ...   \n",
       "\n",
       "      conversion  \\\n",
       "0            NaN   \n",
       "1            NaN   \n",
       "2            0.0   \n",
       "3            0.0   \n",
       "4            NaN   \n",
       "...          ...   \n",
       "5906         NaN   \n",
       "5907         NaN   \n",
       "5908         NaN   \n",
       "5909         NaN   \n",
       "5910         1.0   \n",
       "\n",
       "      type_of_anastomosis -> das von UK sind alles  Ileocolonic anastomosis  \\\n",
       "0                                                   3.0                       \n",
       "1                                                   3.0                       \n",
       "2                                                   3.0                       \n",
       "3                                                   3.0                       \n",
       "4                                                   3.0                       \n",
       "...                                                 ...                       \n",
       "5906                                                3.0                       \n",
       "5907                                                3.0                       \n",
       "5908                                                3.0                       \n",
       "5909                                                3.0                       \n",
       "5910                                                3.0                       \n",
       "\n",
       "      anastomotic_technique  anastomotic_configuration  protective_stomy  \\\n",
       "0                       2.0                        1.0               3.0   \n",
       "1                       1.0                        3.0               3.0   \n",
       "2                       NaN                        1.0               3.0   \n",
       "3                       1.0                        3.0               3.0   \n",
       "4                       1.0                        3.0               3.0   \n",
       "...                     ...                        ...               ...   \n",
       "5906                    2.0                        2.0               3.0   \n",
       "5907                    2.0                        2.0               3.0   \n",
       "5908                    1.0                        3.0               3.0   \n",
       "5909                    2.0                        2.0               3.0   \n",
       "5910                    2.0                        NaN               3.0   \n",
       "\n",
       "      surgeon_experience  anastomotic_leackage  \\\n",
       "0                    1.0                     0   \n",
       "1                    1.0                     0   \n",
       "2                    1.0                     0   \n",
       "3                    1.0                     0   \n",
       "4                    1.0                     0   \n",
       "...                  ...                   ...   \n",
       "5906                 1.0                     0   \n",
       "5907                 1.0                     0   \n",
       "5908                 1.0                     0   \n",
       "5909                 1.0                     0   \n",
       "5910                 NaN                     0   \n",
       "\n",
       "      BIHistoryOfIschaemicHeartDisease  BIHistoryOfDiabetes  \\\n",
       "0                                    0                    0   \n",
       "1                                    0                    0   \n",
       "2                                    0                    0   \n",
       "3                                    0                    0   \n",
       "4                                    1                    0   \n",
       "...                                ...                  ...   \n",
       "5906                                 0                    0   \n",
       "5907                                 0                    0   \n",
       "5908                                 0                    1   \n",
       "5909                                 0                    0   \n",
       "5910                                 0                    0   \n",
       "\n",
       "      data_group_encoded  \n",
       "0                      0  \n",
       "1                      0  \n",
       "2                      0  \n",
       "3                      0  \n",
       "4                      0  \n",
       "...                  ...  \n",
       "5906                  13  \n",
       "5907                  13  \n",
       "5908                  13  \n",
       "5909                  13  \n",
       "5910                  13  \n",
       "\n",
       "[5911 rows x 36 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encode data_group column\n",
    "if 'data_group' in df.columns.tolist():\n",
    "    clinics_2 = df['data_group'].unique().tolist()\n",
    "    code_clinics = {v : k for k , v in enumerate(clinics_2)}\n",
    "    df['data_group_encoded'] = df['data_group'].map(code_clinics)\n",
    "    df = df.drop(columns = ['data_group'])\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputing data using KNN\n",
      "                                                           0\n",
      "pack_years                                          0.703265\n",
      "preoperative_albumin_level                          0.669768\n",
      "liver_metastasis_at_time_of_anastomosis             0.588733\n",
      "tnf_alpha_inhib                                     0.582643\n",
      "preoperative_nsaids_use                             0.577736\n",
      "real_function_ckd_stages                            0.570969\n",
      "preoperative_leukocyte_count                        0.566402\n",
      "alcohol_abuse                                       0.553037\n",
      "protective_stomy                                    0.536457\n",
      "preoperative_blood_transfusion                      0.507528\n",
      "dosage_of_steroids                                  0.506513\n",
      "preoperative_use_of_immunosuppressive_drugs         0.460497\n",
      "preoperative_steroid_use                            0.459313\n",
      "perforation                                         0.416173\n",
      "conversion                                          0.402977\n",
      "preoperative_crp_level                              0.348334\n",
      "anastomotic_configuration                           0.255287\n",
      "neoadjuvant_therapy                                 0.160041\n",
      "bmi                                                 0.074945\n",
      "preoperative_hemoglobin_level                       0.062595\n",
      "surgeon_experience                                  0.057858\n",
      "active_smoking                                      0.046016\n",
      "anastomotic_technique                               0.030113\n",
      "prior_abdominal_surgery                             0.026222\n",
      "approach                                            0.016410\n",
      "asa_score                                           0.006598\n",
      "type_of_anastomosis -> das von UK sind alles  I...  0.003722\n",
      "age                                                 0.001184\n",
      "emergency_surgery                                   0.000677\n",
      "sex                                                 0.000169\n",
      "operation                                           0.000000\n",
      "indication                                          0.000000\n",
      "anastomotic_leackage                                0.000000\n",
      "BIHistoryOfIschaemicHeartDisease                    0.000000\n",
      "BIHistoryOfDiabetes                                 0.000000\n",
      "data_group_encoded                                  0.000000\n",
      "Columns deleted by missing values: ['pack_years', 'preoperative_albumin_level', 'liver_metastasis_at_time_of_anastomosis', 'tnf_alpha_inhib', 'preoperative_nsaids_use', 'real_function_ckd_stages', 'preoperative_leukocyte_count', 'alcohol_abuse', 'protective_stomy', 'preoperative_blood_transfusion', 'dosage_of_steroids', 'preoperative_use_of_immunosuppressive_drugs', 'preoperative_steroid_use', 'perforation', 'conversion', 'preoperative_crp_level', 'anastomotic_configuration']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>bmi</th>\n",
       "      <th>active_smoking</th>\n",
       "      <th>pack_years</th>\n",
       "      <th>alcohol_abuse</th>\n",
       "      <th>real_function_ckd_stages</th>\n",
       "      <th>preoperative_hemoglobin_level</th>\n",
       "      <th>preoperative_leukocyte_count</th>\n",
       "      <th>preoperative_albumin_level</th>\n",
       "      <th>...</th>\n",
       "      <th>conversion</th>\n",
       "      <th>type_of_anastomosis -&gt; das von UK sind alles  Ileocolonic anastomosis</th>\n",
       "      <th>anastomotic_technique</th>\n",
       "      <th>anastomotic_configuration</th>\n",
       "      <th>protective_stomy</th>\n",
       "      <th>surgeon_experience</th>\n",
       "      <th>anastomotic_leackage</th>\n",
       "      <th>BIHistoryOfIschaemicHeartDisease</th>\n",
       "      <th>BIHistoryOfDiabetes</th>\n",
       "      <th>data_group_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>23.96</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.60</td>\n",
       "      <td>6.40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>19.20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.30</td>\n",
       "      <td>12.40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>18.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.70</td>\n",
       "      <td>9.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>22.40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.90</td>\n",
       "      <td>8.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>17.20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.70</td>\n",
       "      <td>8.60</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5906</th>\n",
       "      <td>2.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>20.40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.60</td>\n",
       "      <td>4.90</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5907</th>\n",
       "      <td>2.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>32.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.61</td>\n",
       "      <td>7.27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5908</th>\n",
       "      <td>2.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>22.70</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.70</td>\n",
       "      <td>9.20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5909</th>\n",
       "      <td>1.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>24.30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.20</td>\n",
       "      <td>4.70</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5910</th>\n",
       "      <td>2.0</td>\n",
       "      <td>76.2</td>\n",
       "      <td>14.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>11.01</td>\n",
       "      <td>13.40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5911 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      sex   age    bmi  active_smoking  pack_years  alcohol_abuse  \\\n",
       "0     1.0  87.0  23.96             1.0        25.0            2.0   \n",
       "1     1.0  53.0  19.20             1.0        35.0            3.0   \n",
       "2     2.0  71.0  18.80             0.0        20.7            3.0   \n",
       "3     1.0  39.0  22.40             0.0         0.0            3.0   \n",
       "4     1.0  67.0  17.20             1.0        75.0            3.0   \n",
       "...   ...   ...    ...             ...         ...            ...   \n",
       "5906  2.0  24.0  20.40             0.0         1.0            3.0   \n",
       "5907  2.0  87.0  32.00             0.0        20.3            3.0   \n",
       "5908  2.0  74.0  22.70             1.0        20.0            3.0   \n",
       "5909  1.0  85.0  24.30             0.0        15.9            3.0   \n",
       "5910  2.0  76.2  14.80             0.0        17.5            3.0   \n",
       "\n",
       "      real_function_ckd_stages  preoperative_hemoglobin_level  \\\n",
       "0                          5.0                           9.60   \n",
       "1                          1.0                          11.30   \n",
       "2                          1.0                          13.70   \n",
       "3                          2.0                          11.90   \n",
       "4                          1.0                           7.70   \n",
       "...                        ...                            ...   \n",
       "5906                       1.0                          13.60   \n",
       "5907                       4.0                           9.61   \n",
       "5908                       1.0                           9.70   \n",
       "5909                       2.0                          13.20   \n",
       "5910                       1.8                          11.01   \n",
       "\n",
       "      preoperative_leukocyte_count  preoperative_albumin_level  ...  \\\n",
       "0                             6.40                         0.0  ...   \n",
       "1                            12.40                         0.0  ...   \n",
       "2                             9.00                         0.0  ...   \n",
       "3                             8.80                         0.0  ...   \n",
       "4                             8.60                         0.0  ...   \n",
       "...                            ...                         ...  ...   \n",
       "5906                          4.90                         0.0  ...   \n",
       "5907                          7.27                         0.0  ...   \n",
       "5908                          9.20                         0.0  ...   \n",
       "5909                          4.70                         0.0  ...   \n",
       "5910                         13.40                         0.0  ...   \n",
       "\n",
       "      conversion  \\\n",
       "0            0.5   \n",
       "1            0.5   \n",
       "2            0.0   \n",
       "3            0.0   \n",
       "4            0.6   \n",
       "...          ...   \n",
       "5906         0.2   \n",
       "5907         0.4   \n",
       "5908         0.5   \n",
       "5909         0.5   \n",
       "5910         1.0   \n",
       "\n",
       "      type_of_anastomosis -> das von UK sind alles  Ileocolonic anastomosis  \\\n",
       "0                                                   3.0                       \n",
       "1                                                   3.0                       \n",
       "2                                                   3.0                       \n",
       "3                                                   3.0                       \n",
       "4                                                   3.0                       \n",
       "...                                                 ...                       \n",
       "5906                                                3.0                       \n",
       "5907                                                3.0                       \n",
       "5908                                                3.0                       \n",
       "5909                                                3.0                       \n",
       "5910                                                3.0                       \n",
       "\n",
       "      anastomotic_technique  anastomotic_configuration  protective_stomy  \\\n",
       "0                       2.0                        1.0               3.0   \n",
       "1                       1.0                        3.0               3.0   \n",
       "2                       1.7                        1.0               3.0   \n",
       "3                       1.0                        3.0               3.0   \n",
       "4                       1.0                        3.0               3.0   \n",
       "...                     ...                        ...               ...   \n",
       "5906                    2.0                        2.0               3.0   \n",
       "5907                    2.0                        2.0               3.0   \n",
       "5908                    1.0                        3.0               3.0   \n",
       "5909                    2.0                        2.0               3.0   \n",
       "5910                    2.0                        2.8               3.0   \n",
       "\n",
       "      surgeon_experience  anastomotic_leackage  \\\n",
       "0                    1.0                   0.0   \n",
       "1                    1.0                   0.0   \n",
       "2                    1.0                   0.0   \n",
       "3                    1.0                   0.0   \n",
       "4                    1.0                   0.0   \n",
       "...                  ...                   ...   \n",
       "5906                 1.0                   0.0   \n",
       "5907                 1.0                   0.0   \n",
       "5908                 1.0                   0.0   \n",
       "5909                 1.0                   0.0   \n",
       "5910                 1.0                   0.0   \n",
       "\n",
       "      BIHistoryOfIschaemicHeartDisease  BIHistoryOfDiabetes  \\\n",
       "0                                  0.0                  0.0   \n",
       "1                                  0.0                  0.0   \n",
       "2                                  0.0                  0.0   \n",
       "3                                  0.0                  0.0   \n",
       "4                                  1.0                  0.0   \n",
       "...                                ...                  ...   \n",
       "5906                               0.0                  0.0   \n",
       "5907                               0.0                  0.0   \n",
       "5908                               0.0                  1.0   \n",
       "5909                               0.0                  0.0   \n",
       "5910                               0.0                  0.0   \n",
       "\n",
       "      data_group_encoded  \n",
       "0                    0.0  \n",
       "1                    0.0  \n",
       "2                    0.0  \n",
       "3                    0.0  \n",
       "4                    0.0  \n",
       "...                  ...  \n",
       "5906                13.0  \n",
       "5907                13.0  \n",
       "5908                13.0  \n",
       "5909                13.0  \n",
       "5910                13.0  \n",
       "\n",
       "[5911 rows x 36 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if GLOBAL_PARAMETERS['NAN_HANDLE'] == 'MASK_ALL':\n",
    "    print('All features masked as -1')\n",
    "    df = df.fillna(-1)\n",
    "if GLOBAL_PARAMETERS['NAN_HANDLE'] == 'DROP_ALL':\n",
    "    percent_of_missing = pd.DataFrame((df.replace(-1 , np.nan).isnull().sum() / df.shape[0]).sort_values(ascending = False))\n",
    "    print(percent_of_missing)\n",
    "    to_drop_missing_columns = percent_of_missing[percent_of_missing[0] > 0.2].index.tolist()\n",
    "    print('Columns deleted by missing values:' , to_drop_missing_columns)\n",
    "    df = df.drop(columns = to_drop_missing_columns)\n",
    "    df = df.dropna()\n",
    "    print('Rows with nan dropped')\n",
    "if GLOBAL_PARAMETERS['NAN_HANDLE'] == 'DROP_PERCENT':\n",
    "    print('Maintaining features with certain percent of NaNs')\n",
    "    percent_of_missing = pd.DataFrame((df.replace(-1 , np.nan).isnull().sum() / df.shape[0]).sort_values(ascending = False))\n",
    "    print(percent_of_missing)\n",
    "    to_drop_missing_columns = percent_of_missing[percent_of_missing[0] > 0.2].index.tolist()\n",
    "    print('Columns deleted by missing values:' , to_drop_missing_columns)\n",
    "    df = df.drop(columns = to_drop_missing_columns)\n",
    "if GLOBAL_PARAMETERS['NAN_HANDLE'] == 'KNN':\n",
    "    print('Imputing data using KNN')\n",
    "    percent_of_missing = pd.DataFrame((df.replace(-1 , np.nan).isnull().sum() / df.shape[0]).sort_values(ascending = False))\n",
    "    print(percent_of_missing)\n",
    "    to_drop_missing_columns = percent_of_missing[percent_of_missing[0] > 0.2].index.tolist()\n",
    "    print('Columns deleted by missing values:' , to_drop_missing_columns)\n",
    "    imputer = KNNImputer(n_neighbors = 10)\n",
    "    df = pd.DataFrame(imputer.fit_transform(df) , columns = df.columns.tolist())\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object saved --> ..\\models\\KNN_Imputer_25_9_V2.sav\n"
     ]
    }
   ],
   "source": [
    "# Save imputer\n",
    "imputer_path = r'..\\models\\KNN_Imputer_25_9_V2.sav'\n",
    "pickle.dump(imputer , open(imputer_path , 'wb'))\n",
    "print('Object saved -->' , imputer_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1715801934259,
     "user": {
      "displayName": "Edgar David Varcarcel Trujillo",
      "userId": "04708129325083286457"
     },
     "user_tz": 300
    },
    "id": "sRxQj_luDbsE",
    "outputId": "5bd6d28a-dc22-4d15-e835-86249824ec4b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sex',\n",
       " 'active_smoking',\n",
       " 'alcohol_abuse',\n",
       " 'liver_metastasis_at_time_of_anastomosis',\n",
       " 'neoadjuvant_therapy',\n",
       " 'preoperative_use_of_immunosuppressive_drugs',\n",
       " 'preoperative_steroid_use',\n",
       " 'preoperative_nsaids_use',\n",
       " 'preoperative_blood_transfusion',\n",
       " 'tnf_alpha_inhib',\n",
       " 'prior_abdominal_surgery',\n",
       " 'indication',\n",
       " 'operation',\n",
       " 'emergency_surgery',\n",
       " 'perforation',\n",
       " 'approach',\n",
       " 'conversion',\n",
       " 'type_of_anastomosis -> das von UK sind alles  Ileocolonic anastomosis',\n",
       " 'anastomotic_technique',\n",
       " 'anastomotic_configuration',\n",
       " 'protective_stomy',\n",
       " 'BIHistoryOfIschaemicHeartDisease',\n",
       " 'BIHistoryOfDiabetes',\n",
       " 'data_group_encoded']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define numeric and categorical columns\n",
    "num_columns = ['age' , 'bmi' , 'pack_years' , 'preoperative_hemoglobin_level' , 'preoperative_leukocyte_count',\n",
    "              'preoperative_albumin_level' , 'preoperative_crp_level' , 'dosage_of_steroids']\n",
    "num_columns = [i for i in num_columns if i in df.columns.tolist()]\n",
    "ordinal_columns = ['real_function_ckd_stages' , 'charlson_comorbidity_index' ,\n",
    "                  'asa_score' , 'surgeon_experience']\n",
    "ordinal_columns = [i for i in ordinal_columns if i in df.columns.tolist()]\n",
    "cat_columns = df.drop(columns = num_columns + TARGET + ordinal_columns).columns.tolist()\n",
    "cat_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a73RK0mqKxXV",
    "tags": []
   },
   "source": [
    "# **2. Scaling**\n",
    "1. If YES, then MinMaxScaler is used to numeric features.\n",
    "2. If NO, then no scaling is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaling performed\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>bmi</th>\n",
       "      <th>pack_years</th>\n",
       "      <th>preoperative_hemoglobin_level</th>\n",
       "      <th>preoperative_leukocyte_count</th>\n",
       "      <th>preoperative_albumin_level</th>\n",
       "      <th>preoperative_crp_level</th>\n",
       "      <th>dosage_of_steroids</th>\n",
       "      <th>real_function_ckd_stages</th>\n",
       "      <th>asa_score</th>\n",
       "      <th>...</th>\n",
       "      <th>approach</th>\n",
       "      <th>conversion</th>\n",
       "      <th>type_of_anastomosis -&gt; das von UK sind alles  Ileocolonic anastomosis</th>\n",
       "      <th>anastomotic_technique</th>\n",
       "      <th>anastomotic_configuration</th>\n",
       "      <th>protective_stomy</th>\n",
       "      <th>BIHistoryOfIschaemicHeartDisease</th>\n",
       "      <th>BIHistoryOfDiabetes</th>\n",
       "      <th>data_group_encoded</th>\n",
       "      <th>anastomotic_leackage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.835294</td>\n",
       "      <td>0.212811</td>\n",
       "      <td>0.004630</td>\n",
       "      <td>0.377119</td>\n",
       "      <td>0.047077</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.013769</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.9</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.435294</td>\n",
       "      <td>0.128114</td>\n",
       "      <td>0.006481</td>\n",
       "      <td>0.449153</td>\n",
       "      <td>0.092635</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010327</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.120996</td>\n",
       "      <td>0.003833</td>\n",
       "      <td>0.550847</td>\n",
       "      <td>0.066819</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008606</td>\n",
       "      <td>0.04</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.270588</td>\n",
       "      <td>0.185053</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.474576</td>\n",
       "      <td>0.065300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.049914</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.092527</td>\n",
       "      <td>0.013889</td>\n",
       "      <td>0.296610</td>\n",
       "      <td>0.063781</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.080895</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5906</th>\n",
       "      <td>0.094118</td>\n",
       "      <td>0.149466</td>\n",
       "      <td>0.000185</td>\n",
       "      <td>0.546610</td>\n",
       "      <td>0.035687</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.009122</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5907</th>\n",
       "      <td>0.835294</td>\n",
       "      <td>0.355872</td>\n",
       "      <td>0.003759</td>\n",
       "      <td>0.377542</td>\n",
       "      <td>0.053683</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.044647</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5908</th>\n",
       "      <td>0.682353</td>\n",
       "      <td>0.190391</td>\n",
       "      <td>0.003704</td>\n",
       "      <td>0.381356</td>\n",
       "      <td>0.068337</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.053924</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5909</th>\n",
       "      <td>0.811765</td>\n",
       "      <td>0.218861</td>\n",
       "      <td>0.002944</td>\n",
       "      <td>0.529661</td>\n",
       "      <td>0.034169</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.033046</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5910</th>\n",
       "      <td>0.708235</td>\n",
       "      <td>0.049822</td>\n",
       "      <td>0.003241</td>\n",
       "      <td>0.436864</td>\n",
       "      <td>0.100228</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001549</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5911 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           age       bmi  pack_years  preoperative_hemoglobin_level  \\\n",
       "0     0.835294  0.212811    0.004630                       0.377119   \n",
       "1     0.435294  0.128114    0.006481                       0.449153   \n",
       "2     0.647059  0.120996    0.003833                       0.550847   \n",
       "3     0.270588  0.185053    0.000000                       0.474576   \n",
       "4     0.600000  0.092527    0.013889                       0.296610   \n",
       "...        ...       ...         ...                            ...   \n",
       "5906  0.094118  0.149466    0.000185                       0.546610   \n",
       "5907  0.835294  0.355872    0.003759                       0.377542   \n",
       "5908  0.682353  0.190391    0.003704                       0.381356   \n",
       "5909  0.811765  0.218861    0.002944                       0.529661   \n",
       "5910  0.708235  0.049822    0.003241                       0.436864   \n",
       "\n",
       "      preoperative_leukocyte_count  preoperative_albumin_level  \\\n",
       "0                         0.047077                         0.0   \n",
       "1                         0.092635                         0.0   \n",
       "2                         0.066819                         0.0   \n",
       "3                         0.065300                         0.0   \n",
       "4                         0.063781                         0.0   \n",
       "...                            ...                         ...   \n",
       "5906                      0.035687                         0.0   \n",
       "5907                      0.053683                         0.0   \n",
       "5908                      0.068337                         0.0   \n",
       "5909                      0.034169                         0.0   \n",
       "5910                      0.100228                         0.0   \n",
       "\n",
       "      preoperative_crp_level  dosage_of_steroids  real_function_ckd_stages  \\\n",
       "0                   0.013769                0.00                       5.0   \n",
       "1                   0.010327                0.00                       1.0   \n",
       "2                   0.008606                0.04                       1.0   \n",
       "3                   0.049914                0.00                       2.0   \n",
       "4                   0.080895                0.00                       1.0   \n",
       "...                      ...                 ...                       ...   \n",
       "5906                0.009122                0.00                       1.0   \n",
       "5907                0.044647                0.00                       4.0   \n",
       "5908                0.053924                0.00                       1.0   \n",
       "5909                0.033046                0.00                       2.0   \n",
       "5910                0.001549                0.00                       1.8   \n",
       "\n",
       "      asa_score  ...  approach  conversion  \\\n",
       "0           2.9  ...       1.0         0.5   \n",
       "1           2.0  ...       3.0         0.5   \n",
       "2           4.0  ...       3.0         0.0   \n",
       "3           2.0  ...       3.0         0.0   \n",
       "4           4.0  ...       3.0         0.6   \n",
       "...         ...  ...       ...         ...   \n",
       "5906        2.0  ...       1.0         0.2   \n",
       "5907        3.0  ...       3.0         0.4   \n",
       "5908        3.0  ...       3.0         0.5   \n",
       "5909        3.0  ...       3.0         0.5   \n",
       "5910        1.0  ...       2.8         1.0   \n",
       "\n",
       "      type_of_anastomosis -> das von UK sind alles  Ileocolonic anastomosis  \\\n",
       "0                                                   3.0                       \n",
       "1                                                   3.0                       \n",
       "2                                                   3.0                       \n",
       "3                                                   3.0                       \n",
       "4                                                   3.0                       \n",
       "...                                                 ...                       \n",
       "5906                                                3.0                       \n",
       "5907                                                3.0                       \n",
       "5908                                                3.0                       \n",
       "5909                                                3.0                       \n",
       "5910                                                3.0                       \n",
       "\n",
       "      anastomotic_technique  anastomotic_configuration  protective_stomy  \\\n",
       "0                       2.0                        1.0               3.0   \n",
       "1                       1.0                        3.0               3.0   \n",
       "2                       1.7                        1.0               3.0   \n",
       "3                       1.0                        3.0               3.0   \n",
       "4                       1.0                        3.0               3.0   \n",
       "...                     ...                        ...               ...   \n",
       "5906                    2.0                        2.0               3.0   \n",
       "5907                    2.0                        2.0               3.0   \n",
       "5908                    1.0                        3.0               3.0   \n",
       "5909                    2.0                        2.0               3.0   \n",
       "5910                    2.0                        2.8               3.0   \n",
       "\n",
       "      BIHistoryOfIschaemicHeartDisease  BIHistoryOfDiabetes  \\\n",
       "0                                  0.0                  0.0   \n",
       "1                                  0.0                  0.0   \n",
       "2                                  0.0                  0.0   \n",
       "3                                  0.0                  0.0   \n",
       "4                                  1.0                  0.0   \n",
       "...                                ...                  ...   \n",
       "5906                               0.0                  0.0   \n",
       "5907                               0.0                  0.0   \n",
       "5908                               0.0                  1.0   \n",
       "5909                               0.0                  0.0   \n",
       "5910                               0.0                  0.0   \n",
       "\n",
       "      data_group_encoded  anastomotic_leackage  \n",
       "0                    0.0                   0.0  \n",
       "1                    0.0                   0.0  \n",
       "2                    0.0                   0.0  \n",
       "3                    0.0                   0.0  \n",
       "4                    0.0                   0.0  \n",
       "...                  ...                   ...  \n",
       "5906                13.0                   0.0  \n",
       "5907                13.0                   0.0  \n",
       "5908                13.0                   0.0  \n",
       "5909                13.0                   0.0  \n",
       "5910                13.0                   0.0  \n",
       "\n",
       "[5911 rows x 36 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if GLOBAL_PARAMETERS['PERFORM_SCALING'] == 'YES':\n",
    "    print('Scaling performed\\n')\n",
    "    # Create scaler and one hot encoding obects\n",
    "    numeric_scaler = MinMaxScaler()\n",
    "    # Fit objects\n",
    "    numeric_scaler.fit(df[num_columns])\n",
    "    # Transform data\n",
    "    aux_numeric = pd.DataFrame(numeric_scaler.transform(df[num_columns]) , columns = df[num_columns].columns.tolist())\n",
    "    # Concat data\n",
    "    df = pd.concat([aux_numeric,\n",
    "                    df[ordinal_columns].fillna(-1).reset_index(drop = True),\n",
    "                    df[cat_columns].reset_index(drop = True),\n",
    "                    df[TARGET].fillna(0).reset_index(drop = True)] , axis = 1)\n",
    "if GLOBAL_PARAMETERS['PERFORM_SCALING'] == 'NO':\n",
    "    print('No scaling performed\\n')\n",
    "    #for i in range(len(train_set)):\n",
    "        #train_set[i] = train_set[i].drop(columns = ['data_group']).fillna(-1)\n",
    "        #test_set[i] = test_set[i].drop(columns = ['data_group']).fillna(-1)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object saved --> ..\\models\\Scaler_25_9_V2.sav\n"
     ]
    }
   ],
   "source": [
    "# Save Scaler\n",
    "scaler_path = r'..\\models\\Scaler_25_9_V2.sav'\n",
    "pickle.dump(numeric_scaler , open(scaler_path , 'wb'))\n",
    "print('Object saved -->' , scaler_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **3 Feature Selection**\n",
    "\n",
    "1. If XGBOOST, then a XGBClassifier is trained and select the top n% (default 80%) of the features\n",
    "2. If VARIANCE_THRESHOLD, then Scikit Learn Variance Threshold with default parameters is applied\n",
    "3. If F_CLASSIF, then ANOVA is applied.\n",
    "4. If RFE, then Recursive Feature Elimination is applied.\n",
    "5. If LASSO, then Lasso model is applied.\n",
    "6. If NONE, then no feature selection is applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Selection : ANOVA\n",
      "Maintaining 12 features\n",
      "Features Selected: ['dosage_of_steroids', 'asa_score', 'sex', 'active_smoking', 'alcohol_abuse', 'preoperative_use_of_immunosuppressive_drugs', 'preoperative_steroid_use', 'emergency_surgery', 'perforation', 'approach', 'conversion', 'protective_stomy']\n",
      "Selected Features : ['dosage_of_steroids', 'asa_score', 'sex', 'active_smoking', 'alcohol_abuse', 'preoperative_use_of_immunosuppressive_drugs', 'preoperative_steroid_use', 'emergency_surgery', 'perforation', 'approach', 'conversion', 'protective_stomy', 'anastomotic_leackage']\n"
     ]
    }
   ],
   "source": [
    "if GLOBAL_PARAMETERS['FEATURE_SELECTION'] == 'XGBOOST':\n",
    "    print('Feature Selection : XGBoost Feature Importance')\n",
    "    # Create XGB Model\n",
    "    feature_selection_model = XGBClassifier().fit(df.drop(columns = TARGET),\n",
    "                                                  df[TARGET])\n",
    "    # Extract feature importance from the model\n",
    "    feature_importances = pd.DataFrame({'Feature' : feature_selection_model.feature_names_in_.tolist(),\n",
    "                                       'Importance' : feature_selection_model.feature_importances_.tolist()}).sort_values(by = 'Importance' , ascending = False).reset_index(drop = True)\n",
    "    feature_importances['Cumulative_Importance'] = feature_importances['Importance'].cumsum()\n",
    "    print('Feature Importance for XGBoost:')\n",
    "    print(feature_importances)\n",
    "    # Select top % of features\n",
    "    threshold = 0.8\n",
    "    features_selected = feature_importances[feature_importances['Cumulative_Importance'] <= threshold]['Feature'].tolist()\n",
    "    print('Features Selected:' , features_selected)\n",
    "    df = df[features_selected + TARGET]\n",
    "if GLOBAL_PARAMETERS['FEATURE_SELECTION'] == 'VARIANCE_THRESHOLD':\n",
    "    print('Feature Selection : Variance Threshold')\n",
    "    # Create the object for selection\n",
    "    feature_selection_model = VarianceThreshold()\n",
    "    feature_selection_model.fit(df.drop(columns = TARGET),\n",
    "                                df[TARGET])\n",
    "    features_selected = feature_selection_model.feature_names_in_.tolist()\n",
    "    print('Features Selected:' , features_selected)\n",
    "    df = df[features_selected + TARGET]\n",
    "if GLOBAL_PARAMETERS['FEATURE_SELECTION'] == 'F_CLASSIF':\n",
    "    print('Feature Selection : ANOVA')\n",
    "    threshold = int(0.6 * df.drop(columns = TARGET).shape[1]) # % of features to maintain\n",
    "    print('Maintaining' , threshold , 'features')\n",
    "    feature_selection_model = SelectKBest(f_classif,\n",
    "                                          k=threshold)\n",
    "    feature_selection_model.fit(df.drop(columns = TARGET),\n",
    "                                df[TARGET])\n",
    "    features_selected = feature_selection_model.get_feature_names_out().tolist()\n",
    "    print('Features Selected:' , features_selected)\n",
    "    df = df[features_selected + TARGET]\n",
    "if GLOBAL_PARAMETERS['FEATURE_SELECTION'] == 'RFE':\n",
    "    print('Feature Selection : RFE')\n",
    "    threshold = int(0.6 * df.drop(columns = TARGET).shape[1]) # % of features to maintain\n",
    "    feature_selection_model = RFECV(\n",
    "                                    estimator = XGBClassifier(),\n",
    "                                    step = 1,\n",
    "                                    cv = StratifiedKFold(5),\n",
    "                                    scoring = \"f1_macro\",\n",
    "                                    min_features_to_select = threshold,\n",
    "                                    n_jobs = -1,\n",
    "                                )\n",
    "    feature_selection_model.fit(df.drop(columns = TARGET),\n",
    "                                df[TARGET])\n",
    "    features_selected = feature_selection_model.get_feature_names_out().tolist()\n",
    "    print('Features Selected:' , features_selected)\n",
    "    df = df[features_selected + TARGET]\n",
    "if GLOBAL_PARAMETERS['FEATURE_SELECTION'] == 'NONE':\n",
    "    print('No Feature Selection applied')\n",
    "    \n",
    "print('Selected Features' , ':' , df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Numeric Features: [['dosage_of_steroids']]\n",
      "New Categrocial Features: [['dosage_of_steroids', 'asa_score', 'sex', 'active_smoking', 'alcohol_abuse', 'preoperative_use_of_immunosuppressive_drugs', 'preoperative_steroid_use', 'emergency_surgery', 'perforation', 'approach', 'conversion', 'protective_stomy']]\n"
     ]
    }
   ],
   "source": [
    "# Re define selected categorical and numerical columns\n",
    "new_num_columns = []\n",
    "new_cat_columns = []\n",
    "new_num_columns.append([i for i in num_columns if i in df.columns.tolist()])\n",
    "new_cat_columns.append([i for i in df.columns.tolist() if i not in new_num_columns and i not in TARGET])\n",
    "print('New Numeric Features:' , new_num_columns)\n",
    "print('New Categrocial Features:' , new_cat_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **4. Sampling Method**\n",
    "\n",
    "Depending of the over/under sampling model is selected, then the object is applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oversampling with ADASYN\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dosage_of_steroids</th>\n",
       "      <th>asa_score</th>\n",
       "      <th>sex</th>\n",
       "      <th>active_smoking</th>\n",
       "      <th>alcohol_abuse</th>\n",
       "      <th>preoperative_use_of_immunosuppressive_drugs</th>\n",
       "      <th>preoperative_steroid_use</th>\n",
       "      <th>emergency_surgery</th>\n",
       "      <th>perforation</th>\n",
       "      <th>approach</th>\n",
       "      <th>conversion</th>\n",
       "      <th>protective_stomy</th>\n",
       "      <th>anastomotic_leackage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.04</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10951</th>\n",
       "      <td>0.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10952</th>\n",
       "      <td>0.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10953</th>\n",
       "      <td>0.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.529096</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10954</th>\n",
       "      <td>0.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.612170</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10955</th>\n",
       "      <td>0.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.550862</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10956 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       dosage_of_steroids  asa_score  sex  active_smoking  alcohol_abuse  \\\n",
       "0                    0.00        2.9  1.0             1.0            2.0   \n",
       "1                    0.00        2.0  1.0             1.0            3.0   \n",
       "2                    0.04        4.0  2.0             0.0            3.0   \n",
       "3                    0.00        2.0  1.0             0.0            3.0   \n",
       "4                    0.00        4.0  1.0             1.0            3.0   \n",
       "...                   ...        ...  ...             ...            ...   \n",
       "10951                0.00        3.0  2.0             0.0            3.0   \n",
       "10952                0.00        3.0  2.0             0.0            3.0   \n",
       "10953                0.00        3.0  2.0             0.0            3.0   \n",
       "10954                0.00        3.0  2.0             0.0            3.0   \n",
       "10955                0.00        3.0  2.0             0.0            3.0   \n",
       "\n",
       "       preoperative_use_of_immunosuppressive_drugs  preoperative_steroid_use  \\\n",
       "0                                              0.0                       0.0   \n",
       "1                                              0.0                       0.0   \n",
       "2                                              0.0                       1.0   \n",
       "3                                              0.0                       0.0   \n",
       "4                                              0.0                       0.0   \n",
       "...                                            ...                       ...   \n",
       "10951                                          0.0                       0.0   \n",
       "10952                                          0.0                       0.0   \n",
       "10953                                          0.0                       0.0   \n",
       "10954                                          0.0                       0.0   \n",
       "10955                                          0.0                       0.0   \n",
       "\n",
       "       emergency_surgery  perforation  approach  conversion  protective_stomy  \\\n",
       "0                    0.0          0.0       1.0    0.500000               3.0   \n",
       "1                    0.0          0.0       3.0    0.500000               3.0   \n",
       "2                    1.0          1.0       3.0    0.000000               3.0   \n",
       "3                    1.0          0.0       3.0    0.000000               3.0   \n",
       "4                    0.0          0.0       3.0    0.600000               3.0   \n",
       "...                  ...          ...       ...         ...               ...   \n",
       "10951                0.0          0.0       3.0    0.600000               3.0   \n",
       "10952                0.0          0.0       3.0    0.600000               3.0   \n",
       "10953                0.0          0.0       3.0    0.529096               3.0   \n",
       "10954                0.0          0.0       3.0    0.612170               3.0   \n",
       "10955                0.0          0.0       3.0    0.550862               3.0   \n",
       "\n",
       "       anastomotic_leackage  \n",
       "0                       0.0  \n",
       "1                       0.0  \n",
       "2                       0.0  \n",
       "3                       0.0  \n",
       "4                       0.0  \n",
       "...                     ...  \n",
       "10951                   1.0  \n",
       "10952                   1.0  \n",
       "10953                   1.0  \n",
       "10954                   1.0  \n",
       "10955                   1.0  \n",
       "\n",
       "[10956 rows x 13 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if GLOBAL_PARAMETERS['SAMPLING'] == 'SMOTE':\n",
    "    print('Oversampling with SMOTE')\n",
    "    X = df.drop(columns = TARGET)\n",
    "    Y =df[TARGET]\n",
    "    oversampler = SMOTE()\n",
    "    X_res , Y_res = oversampler.fit_resample(X , Y)\n",
    "    df = pd.concat([X_res ,\n",
    "                    Y_res] , axis = 1)\n",
    "if GLOBAL_PARAMETERS['SAMPLING'] == 'ADASYN':\n",
    "    print('Oversampling with ADASYN')\n",
    "    X = df.drop(columns = TARGET)\n",
    "    Y = df[TARGET]\n",
    "    oversampler = ADASYN()\n",
    "    X_res , Y_res = oversampler.fit_resample(X , Y)\n",
    "    df = pd.concat([X_res ,\n",
    "                    Y_res] , axis = 1)\n",
    "if GLOBAL_PARAMETERS['SAMPLING'] == 'BORDERLINE_SMOTE':\n",
    "    print('Oversampling with Borderline SMOTE')\n",
    "    X = df.drop(columns = TARGET)\n",
    "    Y = df[TARGET]\n",
    "    oversampler = BorderlineSMOTE(random_state=42)\n",
    "    X_res , Y_res = oversampler.fit_resample(X , Y)\n",
    "    df = pd.concat([X_res ,\n",
    "                    Y_res] , axis = 1)\n",
    "if GLOBAL_PARAMETERS['SAMPLING'] == 'NONE':\n",
    "    print('No oversampling applied')\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aNv19lPIGT0V"
   },
   "source": [
    "# **5. Model Training and Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 503,
     "status": "ok",
     "timestamp": 1715802205303,
     "user": {
      "displayName": "Edgar David Varcarcel Trujillo",
      "userId": "04708129325083286457"
     },
     "user_tz": 300
    },
    "id": "Y2PTb7VLJ2H3"
   },
   "outputs": [],
   "source": [
    "# Define functions for evaluation metrics\n",
    "def calculate_confusion_matrix(true_labels, predicted_labels):\n",
    "    # Calculate confusion matrix\n",
    "    tn, fp, fn, tp = confusion_matrix(true_labels, predicted_labels).ravel()\n",
    "\n",
    "    return tn, tp, fp, fn\n",
    "\n",
    "# Define function that takes confusion matrix an compute required metrics\n",
    "def get_metrics(TN,TP,FP,FN):\n",
    "\n",
    "    acc = (TN+TP)/(TN+TP+FN+FP)\n",
    "    precision = TP / (TP + FP)\n",
    "\n",
    "    # Calculate recall\n",
    "    recall = TP / (TP + FN)\n",
    "    # Calulcate specificity\n",
    "    specificity = TN / (TN + FP)\n",
    "\n",
    "    # Calculate False Negative Rate\n",
    "    FNR = FN / (FN + TP)\n",
    "\n",
    "    # Calculate F1 score\n",
    "    f1 = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "    return acc, precision, recall, f1 , specificity , FNR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "executionInfo": {
     "elapsed": 460,
     "status": "ok",
     "timestamp": 1715802207533,
     "user": {
      "displayName": "Edgar David Varcarcel Trujillo",
      "userId": "04708129325083286457"
     },
     "user_tz": 300
    },
    "id": "CEYT3xz8SSgx"
   },
   "outputs": [],
   "source": [
    "# Function to smooth the ROC curve using a moving average\n",
    "def smooth_roc_curve(fpr, tpr, window_size=5):\n",
    "    df = pd.DataFrame({'fpr': fpr, 'tpr': tpr})\n",
    "    df_smoothed = df.rolling(window=window_size).mean().dropna()\n",
    "    # Add (1,1) point at the end\n",
    "    df_smoothed = pd.concat([df_smoothed,\n",
    "                             pd.DataFrame({'fpr' : [1] , 'tpr' : [1]})] , axis = 0)\n",
    "    return df_smoothed['fpr'].values, df_smoothed['tpr'].values\n",
    "\n",
    "\n",
    "# Function to smooth the Precision Recall curve using a moving average\n",
    "def smooth_precision_curve(precision, recall, window_size=5):\n",
    "    df = pd.DataFrame({'precision': precision, 'recall': recall})\n",
    "    df_smoothed = df.rolling(window=window_size).mean().dropna()\n",
    "    # Add (1,0) point at the end\n",
    "    df_smoothed = pd.concat([df_smoothed,\n",
    "                             pd.DataFrame({'precision' : [1] , 'recall' : [0]})] , axis = 0)\n",
    "    return df_smoothed['precision'].values, df_smoothed['recall'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define fully conected model\n",
    "class FullyConnectedModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_sizes, output_size, dropout_prob=0.5):\n",
    "        super(FullyConnectedModel, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_sizes = hidden_sizes\n",
    "        self.output_size = output_size\n",
    "        self.dropout_prob = dropout_prob\n",
    "\n",
    "        layers = []\n",
    "        # Create the hidden layers with linear, batch normalization, and dropout\n",
    "        prev_size = input_size\n",
    "        for hidden_size in hidden_sizes:\n",
    "            layers.append(nn.Linear(prev_size, hidden_size))\n",
    "            layers.append(nn.BatchNorm1d(hidden_size))\n",
    "            layers.append(nn.Dropout(p=self.dropout_prob))\n",
    "            layers.append(nn.ReLU())\n",
    "            prev_size = hidden_size\n",
    "\n",
    "        # Output layer with softmax activation\n",
    "        layers.append(nn.Linear(prev_size, output_size))\n",
    "        layers.append(nn.Softmax(dim = 1))\n",
    "\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "# Define function to save pytorch model for early stopping\n",
    "def checkpoint(model, filename):\n",
    "    torch.save(model.state_dict(), filename)\n",
    "\n",
    "# Define function to load best early stopping pytorch model to continue with the evaluation\n",
    "def resume(model, filename):\n",
    "    model.load_state_dict(torch.load(filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################################################\n",
      "Combination 1 of 1\n",
      "Parameters --> {'hidden_sizes': [100, 100, 50, 100, 100], 'dropout_prob': 0.1, 'class_weights': [1.0, 2.0], 'BATCH_SIZE': 16}\n",
      "--------------------------------------------------\n",
      "Fold 1 of 5\n",
      "Training Model\n",
      "Epoch [1/1000], Train Loss: 0.6029 , Test Loss: 0.6507\n",
      "Epoch [26/1000], Train Loss: 0.5438 , Test Loss: 0.6145\n",
      "Epoch [51/1000], Train Loss: 0.5592 , Test Loss: 0.6139\n",
      "Epoch [76/1000], Train Loss: 0.7867 , Test Loss: 0.6142\n",
      "Epoch [101/1000], Train Loss: 0.4841 , Test Loss: 0.6148\n",
      "Epoch [126/1000], Train Loss: 0.6841 , Test Loss: 0.6155\n",
      "Epoch [151/1000], Train Loss: 0.6187 , Test Loss: 0.6159\n",
      "Epoch [176/1000], Train Loss: 0.6057 , Test Loss: 0.6163\n",
      "Epoch [201/1000], Train Loss: 0.7789 , Test Loss: 0.6165\n",
      "Epoch [226/1000], Train Loss: 0.6431 , Test Loss: 0.6164\n",
      "Epoch [251/1000], Train Loss: 0.5817 , Test Loss: 0.6171\n",
      "Early stopped training at epoch 251\n",
      "Making predictions\n",
      "#########################\n",
      "Evaluation on train set\n",
      "Computing Metrics for train set\n",
      "[[1182 1556]\n",
      " [ 129 2611]]\n",
      "Accuracy: 0.6924059875867105\n",
      "Precision: 0.6265898728101752\n",
      "Recall: 0.9529197080291971\n",
      "False Negative Ratio: 0.04708029197080292\n",
      "F1 Micro: 0.6924059875867105\n",
      "F1 Macro: 0.6699462280562458\n",
      "Making predictions\n",
      "#########################\n",
      "Evaluation on test set\n",
      "Computing Metrics for test set\n",
      "[[ 727 2011]\n",
      " [ 318 2422]]\n",
      "Accuracy: 0.5748448338809785\n",
      "Precision: 0.5463568689375141\n",
      "Recall: 0.8839416058394161\n",
      "False Negative Ratio: 0.11605839416058394\n",
      "F1 Micro: 0.5748448338809785\n",
      "F1 Macro: 0.529830617569432\n",
      "--------------------------------------------------\n",
      "Fold 2 of 5\n",
      "Training Model\n",
      "Epoch [1/1000], Train Loss: 0.6121 , Test Loss: 0.6677\n",
      "Epoch [26/1000], Train Loss: 0.4773 , Test Loss: 0.6242\n",
      "Epoch [51/1000], Train Loss: 0.4641 , Test Loss: 0.6236\n",
      "Epoch [76/1000], Train Loss: 0.4937 , Test Loss: 0.6233\n",
      "Epoch [101/1000], Train Loss: 0.5923 , Test Loss: 0.6232\n",
      "Epoch [126/1000], Train Loss: 0.6359 , Test Loss: 0.6227\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 67\u001b[0m\n\u001b[0;32m     65\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     66\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(x_batch)\n\u001b[1;32m---> 67\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, y_batch)\n\u001b[0;32m     68\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     69\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:1179\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m   1178\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m-> 1179\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mcross_entropy(\u001b[38;5;28minput\u001b[39m, target, weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight,\n\u001b[0;32m   1180\u001b[0m                            ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mignore_index, reduction\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreduction,\n\u001b[0;32m   1181\u001b[0m                            label_smoothing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabel_smoothing)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\functional.py:3059\u001b[0m, in \u001b[0;36mcross_entropy\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[0;32m   3057\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3058\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[1;32m-> 3059\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_nn\u001b[38;5;241m.\u001b[39mcross_entropy_loss(\u001b[38;5;28minput\u001b[39m, target, weight, _Reduction\u001b[38;5;241m.\u001b[39mget_enum(reduction), ignore_index, label_smoothing)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "results_test = pd.DataFrame()\n",
    "results_train = pd.DataFrame()\n",
    "skf = StratifiedKFold(2)\n",
    "# Extract total combinations\n",
    "num_combinations = len(list(product(*GLOBAL_PARAMETERS['PYTORCH_PARAMETERS'].values())))\n",
    "all_combinations = [\n",
    "    {key: value for key, value in zip(GLOBAL_PARAMETERS['PYTORCH_PARAMETERS'].keys(), combo)}\n",
    "    for combo in product(*GLOBAL_PARAMETERS['PYTORCH_PARAMETERS'].values())]\n",
    "# Loop throught all pytorch parameters\n",
    "for i in range(len(all_combinations)):\n",
    "    print('#' * 50)\n",
    "    print('Combination' , i + 1, 'of' , num_combinations)\n",
    "    print('Parameters -->' , all_combinations[i])\n",
    "    # Loop throgut test clinics\n",
    "    for ii , (train_index , test_index) in enumerate(skf.split(df.drop(columns = TARGET) , df[TARGET])):\n",
    "        print('-' * 50)\n",
    "        print('Fold' , ii + 1 , 'of 5')\n",
    "        \n",
    "        # Define X and Y in both train and test sets\n",
    "        X_train = df.loc[train_index].drop(columns = TARGET)\n",
    "        Y_train = df.loc[train_index][TARGET]\n",
    "\n",
    "        X_test = df.loc[test_index].drop(columns = TARGET)\n",
    "        Y_test = df.loc[test_index][TARGET]\n",
    "        \n",
    "        # Convert data to Pytorch tensors\n",
    "        x_train_tensor = torch.FloatTensor(X_train.values)\n",
    "        x_test_tensor = torch.FloatTensor(X_test.values)\n",
    "\n",
    "        y_train_tensor = torch.LongTensor([z[0] for z in Y_train.values.tolist()])\n",
    "        y_test_tensor = torch.LongTensor([z[0] for z in Y_test.values.tolist()])\n",
    "\n",
    "        dataset = torch.utils.data.TensorDataset(x_train_tensor, y_train_tensor)\n",
    "        dataloader = torch.utils.data.DataLoader(dataset, batch_size = all_combinations[i]['BATCH_SIZE'], shuffle=True)\n",
    "        dataset_size = len(dataloader.dataset)\n",
    "        \n",
    "        # Define model\n",
    "        input_size = X_train.shape[1]\n",
    "        hidden_sizes = all_combinations[i]['hidden_sizes']\n",
    "        output_size = 2\n",
    "        dropout_prob = all_combinations[i]['dropout_prob']\n",
    "        model = FullyConnectedModel(input_size, hidden_sizes, output_size, dropout_prob)\n",
    "        # Define the loss function and optimizer\n",
    "        criterion = nn.CrossEntropyLoss(weight = torch.tensor(all_combinations[i]['class_weights']))  # Weights for each class\n",
    "        optimizer = optim.Adam(model.parameters(), lr=0.00001)\n",
    "        \n",
    "        # Define the early stopping criteria\n",
    "        early_stop_thresh = 200\n",
    "        best_val_loss = 1e10\n",
    "        best_epoch = -1\n",
    "\n",
    "        # Define Scheduler for Learning Rate\n",
    "        scheduler = torch.optim.lr_scheduler.LinearLR(optimizer, start_factor=1.0, end_factor=0.1, total_iters=30)\n",
    "        \n",
    "        # Training loop\n",
    "        print('Training Model')\n",
    "        num_epochs = 1_000\n",
    "        aux_val_loss = []\n",
    "        train_loss_history = []\n",
    "        test_loss_history = []\n",
    "        for epoch in range(num_epochs):\n",
    "            for id_batch, (x_batch, y_batch) in enumerate(dataloader):\n",
    "                if x_batch.shape[0] > 1:\n",
    "                    optimizer.zero_grad()\n",
    "                    outputs = model(x_batch)\n",
    "                    loss = criterion(outputs, y_batch)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "            # Scheduler learning rate\n",
    "            before_lr = optimizer.param_groups[0][\"lr\"]\n",
    "            scheduler.step()\n",
    "            after_lr = optimizer.param_groups[0][\"lr\"]\n",
    "            # Eval model for early stop\n",
    "            model.eval()\n",
    "            test_outputs = model(x_test_tensor)\n",
    "            test_loss = criterion(test_outputs , y_test_tensor)\n",
    "            test_loss_history.append(test_loss.item())\n",
    "            train_loss_history.append(loss.item())\n",
    "            if test_loss < best_val_loss:\n",
    "                best_val_loss = test_loss\n",
    "                best_epoch = epoch\n",
    "                checkpoint(model, \"pytorch_\" + str(MODEL_NAME) + \".pth\")\n",
    "            elif epoch - best_epoch > early_stop_thresh:\n",
    "                print(\"Early stopped training at epoch %d\" % epoch)\n",
    "                break  # terminate the training loop\n",
    "            if epoch % 25 == 0:\n",
    "                print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {loss.item():.4f} , Test Loss: {test_loss.item():.4f}')\n",
    "        \n",
    "        # Evaluation on train set\n",
    "        # Load best model\n",
    "        print('Making predictions')\n",
    "        print('#' * 25)\n",
    "        print('Evaluation on train set')\n",
    "        resume(model, \"pytorch_\" + str(MODEL_NAME) + \".pth\")\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            test_outputs = model(x_train_tensor)\n",
    "            test_outputs = test_outputs.squeeze()\n",
    "            predicted = torch.argmax(test_outputs , axis = 1).float()\n",
    "        # Compute metrics for test set\n",
    "        print('Computing Metrics for train set')\n",
    "        predictions = predicted.numpy()\n",
    "        TN, TP, FP, FN = calculate_confusion_matrix(Y_train.values,\n",
    "                                                    predictions)\n",
    "        acc, precision, recall, f1 , specificity, fnr = get_metrics(TN,\n",
    "                                                                    TP,\n",
    "                                                                    FP,\n",
    "                                                                    FN)\n",
    "        f1 = f1_score(Y_train.values , predictions , average = 'micro')\n",
    "        f2 = f1_score(Y_train.values , predictions , average = 'macro')\n",
    "        print(confusion_matrix(Y_train.values , predictions))\n",
    "        print('Accuracy:' , acc)\n",
    "        print('Precision:' , precision)\n",
    "        print('Recall:' , recall)\n",
    "        print('False Negative Ratio:' , fnr)\n",
    "        print('F1 Micro:' , f1)\n",
    "        print('F1 Macro:' , f2 )\n",
    "\n",
    "        # Save results of train set\n",
    "        aux_train =  pd.DataFrame({'Accuracy' : [acc],\n",
    "                          'Precision' : [precision],\n",
    "                          'Recall' : [recall],\n",
    "                          'F1_Micro' : [f1],\n",
    "                          'F1_Macro' : [f2],\n",
    "                          'Specificity' : [specificity],\n",
    "                          'False Negative Ratio' : [fnr],\n",
    "                          'Fold' : [ii],\n",
    "                          'model_parameters' :  [all_combinations[i]]})\n",
    "        results_train = pd.concat([results_train,\n",
    "                                  aux_train])\n",
    "        # Evaluation on test set\n",
    "        # Load best model\n",
    "        print('Making predictions')\n",
    "        print('#' * 25)\n",
    "        print('Evaluation on test set')\n",
    "        resume(model, \"pytorch_\" + str(MODEL_NAME) + \".pth\")\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            test_outputs = model(x_test_tensor)\n",
    "            test_outputs = test_outputs.squeeze()\n",
    "            predicted = torch.argmax(test_outputs , axis = 1).float()\n",
    "        # Compute metrics for test set\n",
    "        print('Computing Metrics for test set')\n",
    "        predictions = predicted.numpy()\n",
    "        TN, TP, FP, FN = calculate_confusion_matrix(Y_test.values,\n",
    "                                                    predictions)\n",
    "        acc, precision, recall, f1 , specificity, fnr = get_metrics(TN,\n",
    "                                                                    TP,\n",
    "                                                                    FP,\n",
    "                                                                    FN)\n",
    "        f1 = f1_score(Y_test.values , predictions , average = 'micro')\n",
    "        f2 = f1_score(Y_test.values , predictions , average = 'macro')\n",
    "        print(confusion_matrix(Y_test.values , predictions))\n",
    "        print('Accuracy:' , acc)\n",
    "        print('Precision:' , precision)\n",
    "        print('Recall:' , recall)\n",
    "        print('False Negative Ratio:' , fnr)\n",
    "        print('F1 Micro:' , f1)\n",
    "        print('F1 Macro:' , f2 )\n",
    "        # Save results of train set\n",
    "        aux_test =  pd.DataFrame({'Accuracy' : [acc],\n",
    "                          'Precision' : [precision],\n",
    "                          'Recall' : [recall],\n",
    "                          'F1_Micro' : [f1],\n",
    "                          'F1_Macro' : [f2],\n",
    "                          'Specificity' : [specificity],\n",
    "                          'False Negative Ratio' : [fnr],\n",
    "                          'model_parameters' :  [all_combinations[i]],\n",
    "                          'Fold' : [ii]})\n",
    "        results_test = pd.concat([results_test,\n",
    "                                  aux_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EwdtpqrqZNiJ"
   },
   "source": [
    "# **3. Export Results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_path = r'..\\results'\n",
    "output_filename = r'\\Results_25_9_V2_' + MODEL_NAME + '.xlsx' \n",
    "with pd.ExcelWriter(output_path + output_filename) as export:\n",
    "    results_train.to_excel(export , sheet_name = 'train')\n",
    "    results_test.to_excel(export , sheet_name = 'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# **4. Feature Importance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Train model with the best hyperparameters\n",
    "# Define X and Y in both train and test sets\n",
    "X_train = df.loc[train_index].drop(columns = TARGET)\n",
    "Y_train = df.loc[train_index][TARGET]\n",
    "\n",
    "X_test = df.loc[test_index].drop(columns = TARGET)\n",
    "Y_test = df.loc[test_index][TARGET]\n",
    "\n",
    "# Convert data to Pytorch tensors\n",
    "x_train_tensor = torch.FloatTensor(X_train.values)\n",
    "x_test_tensor = torch.FloatTensor(X_test.values)\n",
    "\n",
    "y_train_tensor = torch.LongTensor([z[0] for z in Y_train.values.tolist()])\n",
    "y_test_tensor = torch.LongTensor([z[0] for z in Y_test.values.tolist()])\n",
    "\n",
    "dataset = torch.utils.data.TensorDataset(x_train_tensor, y_train_tensor)\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size = 64, shuffle=True)\n",
    "dataset_size = len(dataloader.dataset)\n",
    "\n",
    "# Define model\n",
    "input_size = X_train.shape[1]\n",
    "hidden_sizes = [100, 100, 50, 100, 100]\n",
    "output_size = 2\n",
    "dropout_prob = 0.1\n",
    "model = FullyConnectedModel(input_size, hidden_sizes, output_size, dropout_prob)\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss(weight = torch.tensor([1.0 , 2.0]))  # Weights for each class\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.00001)\n",
    "\n",
    "# Define the early stopping criteria\n",
    "early_stop_thresh = 200\n",
    "best_val_loss = 1e10\n",
    "best_epoch = -1\n",
    "\n",
    "# Define Scheduler for Learning Rate\n",
    "scheduler = torch.optim.lr_scheduler.LinearLR(optimizer, start_factor=1.0, end_factor=0.1, total_iters=30)\n",
    "\n",
    "# Training loop\n",
    "print('Training Model')\n",
    "num_epochs = 1_000\n",
    "aux_val_loss = []\n",
    "train_loss_history = []\n",
    "test_loss_history = []\n",
    "for epoch in range(num_epochs):\n",
    "    for id_batch, (x_batch, y_batch) in enumerate(dataloader):\n",
    "        if x_batch.shape[0] > 1:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(x_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    # Scheduler learning rate\n",
    "    before_lr = optimizer.param_groups[0][\"lr\"]\n",
    "    scheduler.step()\n",
    "    after_lr = optimizer.param_groups[0][\"lr\"]\n",
    "    # Eval model for early stop\n",
    "    model.eval()\n",
    "    test_outputs = model(x_test_tensor)\n",
    "    test_loss = criterion(test_outputs , y_test_tensor)\n",
    "    test_loss_history.append(test_loss.item())\n",
    "    train_loss_history.append(loss.item())\n",
    "    if test_loss < best_val_loss:\n",
    "        best_val_loss = test_loss\n",
    "        best_epoch = epoch\n",
    "        checkpoint(model, \"pytorch_\" + str(MODEL_NAME) + \".pth\")\n",
    "    elif epoch - best_epoch > early_stop_thresh:\n",
    "        print(\"Early stopped training at epoch %d\" % epoch)\n",
    "        break  # terminate the training loop\n",
    "    if epoch % 25 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {loss.item():.4f} , Test Loss: {test_loss.item():.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create Pytorch Model Wrapper\n",
    "class PyTorchModelWrapper(nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super(PyTorchModelWrapper, self).__init__()\n",
    "        self.model = model\n",
    "\n",
    "    def forward(self, x):\n",
    "        return F.softmax(self.model(x), dim=1)\n",
    "\n",
    "# Create wrapper object\n",
    "wrapped_model = PyTorchModelWrapper(model)\n",
    "\n",
    "# Create explainer\n",
    "explainer = shap.DeepExplainer(wrapped_model, x_test_tensor)\n",
    "instance_idx = 0\n",
    "X_instance = x_test_tensor[instance_idx].unsqueeze(0)\n",
    "shap_values = explainer.shap_values(shap.sample(x_test_tensor , 100) , check_additivity=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Summary plot for class 0\n",
    "shap.summary_plot(shap_values[: , : , 0],\n",
    "                  plot_type = 'bar',\n",
    "                  feature_names = X.columns.tolist(),\n",
    "                 title = 'Feature Importance for Class 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Summary plot for class 1\n",
    "shap.summary_plot(shap_values[: , : , 1],\n",
    "                  plot_type = 'bar',\n",
    "                  feature_names = X.columns.tolist(),\n",
    "                 title = 'Feature Importance for Class 0')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
